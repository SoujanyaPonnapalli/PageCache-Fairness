# Fairness Benchmark Configuration
# Dual-client concurrent execution: steady client vs bursty client
#
# Both clients run simultaneously to demonstrate pagecache fairness issues

[client1_steady]
description = Steady client - sequential reads on 1G file
file_size = 1G
# Phase 0: Warm up for a minute
phase_0_numjobs = 8
phase_0_runtime = 60
phase_0_pattern = write
phase_0_block_size = 2M
phase_0_iodepth = 2
phase_0_ioengine = sync
# Phase 1: Sequential read for 30s
phase_1_numjobs = 8
phase_1_runtime = 30
phase_1_pattern = write
phase_1_block_size = 2M
phase_1_iodepth = 2
phase_1_ioengine = sync
# Phase 2: Sequential read for 30s
phase_2_numjobs = 8
phase_2_runtime = 30
phase_2_pattern = write
phase_2_block_size = 2M
phase_2_iodepth = 2
phase_2_ioengine = sync

[client2_bursty]
description = Bursty client - random reads on 1G file
file_size = 1G
# Phase 0: Warmup for a minute
phase_0_numjobs = 8
phase_0_runtime = 60
phase_0_pattern = write
phase_0_block_size = 2M
phase_0_iodepth = 2
phase_0_ioengine = sync
# Phase 1: Sequential read for 30s
phase_1_numjobs = 8
phase_1_runtime = 30
phase_1_pattern = write
phase_1_block_size = 2M
phase_1_iodepth = 2
phase_1_ioengine = sync
# Phase 2: Random read for 30s
phase_2_numjobs = 8
phase_2_runtime = 30
phase_2_pattern = write
phase_2_block_size = 2M
phase_2_iodepth = 2
phase_2_ioengine = sync

